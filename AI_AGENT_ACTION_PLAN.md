# AlphaTrade System - AI Agent Action Plan
# JPMorgan Seviyesi Backtest Sistemi Ä°Ã§in Komut DÃ¶kÃ¼manÄ±

**Tarih:** 17 AralÄ±k 2025  
**AmaÃ§:** DaÄŸÄ±nÄ±k kodu tek komutla Ã§alÄ±ÅŸan JPMorgan seviyesi backtest sistemine dÃ¶nÃ¼ÅŸtÃ¼rmek  
**Format:** AI Agent'a verilecek sÄ±ralÄ± komutlar

---

# BÃ–LÃœM 1: TESPÄ°T EDÄ°LEN KRÄ°TÄ°K HATALAR

## ğŸ”´ KRÄ°TÄ°K HATA #1: Dosya Ä°simlendirme UyumsuzluÄŸu

**Konum:** `scripts/generate_sample_data.py` satÄ±r 85 ve `src/data/loaders/data_loader.py` satÄ±r 70

**Problem AÃ§Ä±klamasÄ±:**
- DataLoader `AAPL_15min.csv` formatÄ±nda dosya arÄ±yor
- Ama generate_sample_data.py `AAPL.csv` formatÄ±nda oluÅŸturuyor
- SonuÃ§: Sistem 0 sembol buluyor

**Mevcut Durum:**
```
data/raw/ klasÃ¶rÃ¼nde:
- AAPL_15min.csv âœ“ (doÄŸru format - zaten var)
- generate_sample_data.py yanlÄ±ÅŸ format Ã¼retiyor
```

**AI Agent Komutu:**
```
DOSYA: scripts/generate_sample_data.py
SATIR 85 CIVARINDA BUL: filepath = output_path / f"{symbol}.csv"
DEÄÄ°ÅTÄ°R: filepath = output_path / f"{symbol}_15min.csv"

AYRICA SATIR 56 CIVARINDA BUL: "date" column name
DEÄÄ°ÅTÄ°R: "timestamp" olmalÄ± (DataLoader bunu bekliyor)
```

---

## ğŸ”´ KRÄ°TÄ°K HATA #2: Feature Pipeline'da Data Leakage

**Konum:** `main.py` fonksiyon `generate_features()` satÄ±r 340-400

**Problem AÃ§Ä±klamasÄ±:**
- `FeaturePipeline` sÄ±nÄ±fÄ± `fit()` ve `transform()` metodlarÄ±na sahip
- AMA main.py bunlarÄ± KULLANMIYOR
- Direkt `TechnicalIndicators.generate_all_features()` Ã§aÄŸÄ±rÄ±yor
- Scaling parametreleri (mean, std) TÃœM data Ã¼zerinden hesaplanÄ±yor
- Bu GELECEK BÄ°LGÄ°SÄ°NÄ° geÃ§miÅŸe sÄ±zdÄ±rÄ±yor

**Neden Kritik:**
JPMorgan'da bu hata milyonlarca dolarlÄ±k yanlÄ±ÅŸ kararlara yol aÃ§ar. Backtest sonuÃ§larÄ± gerÃ§ekÃ§i deÄŸil.

**AI Agent Komutu:**
```
DOSYA: main.py
FONKSÄ°YON: generate_features()

MEVCUT YAKLAÅIMI SÄ°L (TechnicalIndicators direkt kullanÄ±mÄ±)

YENÄ° YAKLAÅIM:
1. FeaturePipeline instance oluÅŸtur
2. Train data Ã¼zerinde pipeline.fit() Ã§aÄŸÄ±r
3. TÃ¼m data iÃ§in pipeline.transform() Ã§aÄŸÄ±r
4. ASLA fit_transform() tek seferde tÃ¼m data Ã¼zerinde Ã§aÄŸÄ±rma

MANTIK:
- Scaling parametreleri SADECE train data'dan Ã¶ÄŸrenilmeli
- Test data'ya aynÄ± parametreler UYGULANMALI
- Bu ÅŸekilde gelecek bilgisi sÄ±zmaz
```

---

## ğŸ”´ KRÄ°TÄ°K HATA #3: Cross-Validation Purge Gap UygulanmÄ±yor

**Konum:** `main.py` fonksiyon `train_ml_model()` satÄ±r 540-620

**Problem AÃ§Ä±klamasÄ±:**
- `purge_gap` hesaplanÄ±yor (doÄŸru formÃ¼l var)
- `PurgedKFoldCV` oluÅŸturuluyor (doÄŸru sÄ±nÄ±f var)
- AMA sonra sklearn'Ã¼n `cross_validate()` fonksiyonu Ã§aÄŸrÄ±lÄ±yor
- sklearn'Ã¼n cross_validate'i PURGE GAP'I UYGULAMIYOR!
- Custom CV splitter'Ä±n split() metodu hiÃ§ Ã§alÄ±ÅŸmÄ±yor

**SonuÃ§:** Train ve test setleri arasÄ±nda veri sÄ±zÄ±ntÄ±sÄ± var. Model olduÄŸundan iyi gÃ¶rÃ¼nÃ¼yor.

**AI Agent Komutu:**
```
DOSYA: main.py
FONKSÄ°YON: train_ml_model()

sklearn cross_validate() Ã‡AÄRISINI KALDIR

MANUEL CV DÃ–NGÃœSÃœ YAZ:
1. cv.split(X, y) ile fold indekslerini al
2. Her fold iÃ§in:
   a. train_idx ve test_idx ayÄ±r
   b. Leakage kontrolÃ¼ yap (set kesiÅŸimi boÅŸ olmalÄ±)
   c. Model oluÅŸtur ve train_idx Ã¼zerinde eÄŸit
   d. test_idx Ã¼zerinde skorla
   e. Skoru listeye ekle
3. TÃ¼m fold skorlarÄ±nÄ±n ortalamasÄ±nÄ± al

PURGE GAP HESAPLAMASI:
purge_gap = prediction_horizon + max_feature_lookback + buffer
Ã–rnek: 5 + 200 + 10 = 215 bar
```

---

## ğŸ”´ KRÄ°TÄ°K HATA #4: TimescaleDB Entegre DeÄŸil

**Konum:** `src/data/storage/timescale_client.py` (tam implementasyon var) vs `main.py` (hiÃ§ kullanmÄ±yor)

**Problem AÃ§Ä±klamasÄ±:**
- 800+ satÄ±rlÄ±k profesyonel TimescaleDB client yazÄ±lmÄ±ÅŸ
- Connection pooling, retry logic, batch insert var
- Continuous aggregates, compression, retention policies var
- AMA main.py SADECE CSV dosyalarÄ±ndan okuma yapÄ±yor
- TimescaleDB'nin tÃ¼m avantajlarÄ± kullanÄ±lmÄ±yor

**AI Agent Komutu:**
```
DOSYA: main.py
FONKSÄ°YON: load_data()

KONTROL EKLE:
1. Config'de "use_timescale: true" var mÄ±?
2. TIMESCALE_AVAILABLE flag'i True mu?
3. Evetse TimescaleClient kullan
4. HayÄ±rsa mevcut CSV loading'e devam et

TÄ°MESCALE KULLANIMI Ä°Ã‡Ä°N:
1. ConnectionConfig oluÅŸtur (host, port, database, user, password)
2. TimescaleClient context manager ile aÃ§
3. client.get_ohlcv(symbol, start, end, "15min") ile data Ã§ek
4. DataFrame formatÄ±na Ã§evir ve dÃ¶ndÃ¼r

CONFIG DOSYASINA EKLE (config/trading_config.yaml):
timescale:
  enabled: false  # true yapÄ±nca aktif olur
  host: localhost
  port: 5432
  database: alphatrade_db
  user: alphatrade
  password: ""
```

---

## ğŸ”´ KRÄ°TÄ°K HATA #5: Market Impact Modeli YanlÄ±ÅŸ ADV KullanÄ±yor

**Konum:** `main.py` fonksiyon `run_backtest()` satÄ±r 430-490

**Problem AÃ§Ä±klamasÄ±:**
- `calculate_symbol_adv()` her sembol iÃ§in ADV hesaplÄ±yor (doÄŸru)
- Sonra `np.mean()` ile ORTALAMA alÄ±nÄ±yor (yanlÄ±ÅŸ!)
- AlmgrenChrissModel bu ortalama ADV ile oluÅŸturuluyor
- Her trade iÃ§in AYNI ortalama ADV kullanÄ±lÄ±yor

**SonuÃ§:**
- AAPL gibi likit hisseler iÃ§in market impact FAZLA hesaplanÄ±yor
- KÃ¼Ã§Ã¼k hisseler iÃ§in market impact AZ hesaplanÄ±yor
- Backtest sonuÃ§larÄ± gerÃ§ekÃ§i deÄŸil

**AI Agent Komutu:**
```
DOSYA: main.py ve src/backtesting/engine.py

DEÄÄ°ÅÄ°KLÄ°K 1 - main.py:
symbol_adv dictionary'sini BacktestEngine'e PARAMETRE olarak geÃ§ir

DEÄÄ°ÅÄ°KLÄ°K 2 - engine.py BacktestEngine.run():
Her trade iÃ§in o sembolÃ¼n KENDÄ° ADV'sini kullan:
- trade sembolÃ¼nÃ¼ al
- symbol_adv[symbol] ile o sembolÃ¼n ADV'sini bul
- market_impact.calculate_impact(trade_value, symbol_adv) Ã§aÄŸÄ±r

DOÄRU MANTIK:
- AAPL (ADV: $10B) iÃ§in 1M$'lÄ±k trade = minimal impact
- KÃ¼Ã§Ã¼k hisse (ADV: $10M) iÃ§in 1M$'lÄ±k trade = bÃ¼yÃ¼k impact
```

---

## ğŸŸ¡ ORTA SEVÄ°YE HATA #6: Walk-Forward Validation BaÄŸlÄ± DeÄŸil

**Konum:** `config/trading_config.yaml` satÄ±r 85-92 ve `main.py`

**Problem AÃ§Ä±klamasÄ±:**
- Config dosyasÄ±nda walk_forward ayarlarÄ± var:
  ```yaml
  walk_forward:
    enabled: true
    train_period_days: 126
    test_period_days: 21
  ```
- AMA main.py bu ayarlarÄ± HÄ°Ã‡ OKUMUYOR
- WalkForwardValidator sÄ±nÄ±fÄ± MEVCUT ama kullanÄ±lmÄ±yor
- Sistem sadece PurgedKFoldCV kullanÄ±yor

**AI Agent Komutu:**
```
DOSYA: main.py
FONKSÄ°YON: train_ml_model()

WALK-FORWARD KONTROLÃœ EKLE:
1. config["backtest"]["walk_forward"]["enabled"] oku
2. True ise WalkForwardValidator kullan
3. False ise mevcut CV'ye devam et

WalkForwardValidator PARAMETRELERI:
- train_period = train_period_days * 26 (gÃ¼nde 26 bar)
- test_period = test_period_days * 26
- step_size = test_period (non-overlapping)
- expanding = config'deki "anchored" deÄŸeri
- purge_gap = hesaplanan purge_gap

WALK-FORWARD AVANTAJI:
- GerÃ§ek trading'i simÃ¼le eder
- Her dÃ¶nem iÃ§in model yeniden eÄŸitilir
- Out-of-sample performance daha gerÃ§ekÃ§i
```

---

## ğŸŸ¡ ORTA SEVÄ°YE HATA #7: Survivorship Bias DÃ¼zeltmesi Pasif

**Konum:** `main.py` fonksiyon `load_data()` satÄ±r 230-250

**Problem AÃ§Ä±klamasÄ±:**
- Kod `symbol_metadata.json` dosyasÄ±nÄ± arÄ±yor
- Bu dosya YOK (sadece .gitkeep var)
- UniverseManager hiÃ§bir zaman aktif olmuyor
- SonuÃ§: Sadece hayatta kalan hisseler test ediliyor
- Backtest sonuÃ§larÄ± aÅŸÄ±rÄ± iyimser

**Survivorship Bias Nedir:**
- 2010'da 100 hisse vardÄ±
- 20 tanesi battÄ±/delisted oldu
- BugÃ¼n sadece 80 hisse var
- Sadece bu 80 Ã¼zerinde test yapmak = sadece baÅŸarÄ±lÄ±larÄ± test etmek

**AI Agent Komutu:**
```
YENÄ° DOSYA OLUÅTUR: scripts/generate_universe_metadata.py

Ä°Ã‡ERÄ°K:
1. data/raw/ klasÃ¶rÃ¼ndeki tÃ¼m sembolleri listele
2. Her sembol iÃ§in metadata oluÅŸtur:
   - listing_date: Ä°lk veri tarihi
   - delisting_date: null (veya son veri tarihi)
   - sector: SektÃ¶r bilgisi
   - is_active: true/false
3. JSON dosyasÄ±na kaydet: data/raw/symbol_metadata.json

SONRA main.py'de:
UniverseManager aktif olacak
Backtest baÅŸlangÄ±Ã§ tarihindeki universe kullanÄ±lacak
O tarihte mevcut olmayan hisseler dahil edilmeyecek
```

---

## ğŸŸ¡ ORTA SEVÄ°YE HATA #8: Deflated Sharpe Ratio Raporlarda Yok

**Konum:** `src/backtesting/metrics.py` (hesaplama VAR) vs `src/backtesting/reports/` (kullanÄ±lmÄ±yor)

**Problem AÃ§Ä±klamasÄ±:**
- `calculate_deflated_sharpe_ratio()` fonksiyonu mevcut ve doÄŸru
- `calculate_sharpe_statistics()` tam SharpeStatistics dÃ¶ndÃ¼rÃ¼yor
- AMA raporlar sadece NORMAL Sharpe gÃ¶steriyor
- DSR, PSR, MinTRL hiÃ§bir raporda yok

**Neden Kritik:**
JPMorgan'da normal Sharpe'a bakÄ±lmaz. Multiple testing iÃ§in dÃ¼zeltilmiÅŸ DSR bakÄ±lÄ±r.
10 strateji test edip en iyi Sharpe'Ä± seÃ§mek = ÅŸans eseri iyi sonuÃ§ bulmak.

**AI Agent Komutu:**
```
DOSYA: src/backtesting/reports/report_generator.py

calculate_sharpe_statistics() IMPORT ET

RAPOR OLUÅTURURKEN:
1. n_trials parametresi al (kaÃ§ strateji test edildi)
2. Her strateji iÃ§in SharpeStatistics hesapla
3. Rapora EKLE:
   - Deflated Sharpe Ratio (DSR)
   - Probabilistic Sharpe Ratio (PSR) 
   - Minimum Track Record Length (ay)
   - Is Statistically Significant (Evet/HayÄ±r)

TABLO FORMATINDA GÃ–STER:
| Strateji | Return | Sharpe | DSR | PSR | Significant |
|----------|--------|--------|-----|-----|-------------|
| Momentum | 15%    | 1.2    | 0.8 | 89% | Evet        |
| MeanRev  | 8%     | 0.7    | 0.3 | 62% | HayÄ±r       |
```

---

# BÃ–LÃœM 2: EKSÄ°K FONKSÄ°YONELLÄ°KLER

## ğŸ“Œ EKSÄ°K #1: Tek Komutla Ã‡alÄ±ÅŸtÄ±rma

**Mevcut Durum:**
- `python main.py` Ã§alÄ±ÅŸÄ±yor AMA Ã§ok fazla parametre var
- KullanÄ±cÄ± hangi mode, engine, model kullanacaÄŸÄ±nÄ± bilmeli
- Hata durumunda ne yapacaÄŸÄ± belirsiz

**AI Agent Komutu:**
```
YENÄ° DOSYA OLUÅTUR: orchestrate.py

BU DOSYA TEK ENTRY POINT OLMALI

KULLANIM:
python orchestrate.py                    # Her ÅŸeyi Ã§alÄ±ÅŸtÄ±r
python orchestrate.py --quick            # ML training atla
python orchestrate.py --validate-only    # Sadece data kontrol
python orchestrate.py --holdout 0.2      # %20 holdout ayÄ±r

Ä°Ã‡ YAPI:
1. Banner gÃ¶ster (versiyon, tarih, mode)
2. Config yÃ¼kle
3. Data yÃ¼kle ve validate et
4. EÄŸer data yoksa veya hatalÄ±ysa -> hata mesajÄ± ve Ã§Ä±k
5. Feature generate et (leakage-safe)
6. ML model eÄŸit (purged CV ile)
7. TÃ¼m stratejileri backtest et
8. Ensemble oluÅŸtur ve test et
9. Institutional-grade rapor Ã¼ret
10. Holdout validation (varsa)
11. SonuÃ§ Ã¶zeti gÃ¶ster

HER ADIMDA:
- Progress gÃ¶ster
- Hata olursa anlaÅŸÄ±lÄ±r mesaj ver
- Log'a yaz
```

---

## ğŸ“Œ EKSÄ°K #2: Pre-Flight Data Validation

**Mevcut Durum:**
- DataValidator sÄ±nÄ±fÄ± var ve iyi Ã§alÄ±ÅŸÄ±yor
- AMA backtest baÅŸlamadan Ã¶nce TÃœM data kontrol edilmiyor
- Tek bir bozuk sembol tÃ¼m backtest'i bozabiliyor

**AI Agent Komutu:**
```
YENÄ° DOSYA OLUÅTUR: scripts/validate_all_data.py

FONKSÄ°YON:
1. data/raw/ klasÃ¶rÃ¼ndeki TÃœM dosyalarÄ± tara
2. Her dosya iÃ§in:
   - Format kontrolÃ¼ (timestamp, OHLCV kolonlarÄ±)
   - Missing value kontrolÃ¼ (max %5)
   - Fiyat anomalisi kontrolÃ¼ (tek bar'da max %50 deÄŸiÅŸim)
   - Volume kontrolÃ¼ (negatif olmamalÄ±)
   - Tarih sÄ±ralamasÄ± kontrolÃ¼ (monotonic increasing)
3. SonuÃ§larÄ± tablo olarak gÃ¶ster
4. HatalÄ± dosya varsa listele
5. Exit code: 0 (baÅŸarÄ±lÄ±) veya 1 (hatalÄ±)

BACKTEST'TEN Ã–NCE Ã‡ALIÅTIR:
python scripts/validate_all_data.py
EÄŸer exit code 1 ise backtest baÅŸlamasÄ±n
```

---

## ğŸ“Œ EKSÄ°K #3: Transaction Cost Sensitivity Analysis

**Mevcut Durum:**
- Tek bir commission ve slippage deÄŸeri kullanÄ±lÄ±yor
- Backtest sonucu bu deÄŸerlere Ã§ok hassas olabilir
- JPMorgan'da farklÄ± cost senaryolarÄ± test edilmeli

**AI Agent Komutu:**
```
YENÄ° FONKSÄ°YON EKLE: main.py veya orchestrate.py

FONKSÄ°YON ADI: run_cost_sensitivity()

MANTIK:
1. Commission deÄŸerleri: [0.0005, 0.001, 0.002, 0.005]
2. Slippage deÄŸerleri: [0.0002, 0.0005, 0.001, 0.002]
3. Her kombinasyon iÃ§in backtest Ã§alÄ±ÅŸtÄ±r
4. SonuÃ§larÄ± matris olarak gÃ¶ster:

         | Slip 0.02% | Slip 0.05% | Slip 0.1% | Slip 0.2% |
---------|------------|------------|-----------|-----------|
Comm 0.05%|   12.5%   |   11.2%    |   9.8%    |   7.1%    |
Comm 0.1% |   11.8%   |   10.5%    |   9.1%    |   6.4%    |
Comm 0.2% |   10.4%   |    9.1%    |   7.7%    |   5.0%    |

YORUM:
- Strateji cost'a ne kadar hassas?
- Hangi cost seviyesinde karlÄ±lÄ±k kayboluyor?
- Break-even cost nedir?
```

---

## ğŸ“Œ EKSÄ°K #4: Out-of-Sample Holdout Validation

**Mevcut Durum:**
- TÃœM data train ve backtest iÃ§in kullanÄ±lÄ±yor
- GerÃ§ek out-of-sample test yok
- Model overfit olmuÅŸ olabilir ve bilemeyiz

**AI Agent Komutu:**
```
DEÄÄ°ÅÄ°KLÄ°K: load_data() fonksiyonu

YENÄ° PARAMETRE: holdout_pct (default: 0.0)

MANTIK:
1. Data yÃ¼kle
2. holdout_pct > 0 ise:
   - Son %X'i ayÄ±r (holdout_data)
   - Geri kalanÄ± train_data
3. Train/backtest SADECE train_data Ã¼zerinde
4. En iyi strateji belirlendikten SONRA
5. Holdout_data Ã¼zerinde FINAL test
6. Bu sonuÃ§ "gerÃ§ek" out-of-sample performance

NEDEN Ã–NEMLÄ°:
- Backtest'te 10 strateji test ettin
- En iyi Sharpe 1.5 olan seÃ§ildi
- AMA bu "data snooping" olabilir
- Holdout'ta 0.8 gelirse gerÃ§ek performance o
```

---

## ğŸ“Œ EKSÄ°K #5: Regime-Aware Backtest

**Mevcut Durum:**
- Tek bir backtest tÃ¼m dÃ¶nem iÃ§in yapÄ±lÄ±yor
- Bull market, bear market, sideways ayrÄ± ayrÄ± analiz yok
- Strateji belirli rejimlerde kÃ¶tÃ¼ olabilir

**AI Agent Komutu:**
```
MEVCUT SINIF KULLAN: src/features/regime/volatility_regime.py

BACKTEST SONRASI ANALÄ°Z:
1. TÃ¼m dÃ¶nem iÃ§in volatilite rejimi belirle
2. GÃ¼nleri kategorize et: low_vol, normal_vol, high_vol, crisis
3. Her rejim iÃ§in ayrÄ± metrikler hesapla:

   | Rejim    | GÃ¼n | Return | Sharpe | MaxDD |
   |----------|-----|--------|--------|-------|
   | Low Vol  | 150 | +8%    | 1.8    | -3%   |
   | Normal   | 200 | +12%   | 1.2    | -8%   |
   | High Vol | 80  | -5%    | -0.3   | -15%  |
   | Crisis   | 20  | -10%   | -1.5   | -25%  |

YORUM:
- Strateji hangi rejimlerde iyi/kÃ¶tÃ¼?
- Crisis'te hedge var mÄ±?
- Volatilite spike'ta ne oluyor?
```

---

# BÃ–LÃœM 3: KALDIRILMASI GEREKEN FAZLALIKLAR

## ğŸ—‘ï¸ FAZLALIK #1: Duplicate Validation Logic

**Konum:** 
- `src/data/validators/data_validator.py` - DataValidator sÄ±nÄ±fÄ±
- `main.py` satÄ±r 160-195 - validate_data_for_backtest() fonksiyonu

**Problem:** AynÄ± validation logic iki yerde yazÄ±lmÄ±ÅŸ

**AI Agent Komutu:**
```
DOSYA: main.py
SÄ°L: validate_data_for_backtest() fonksiyonunu tamamen kaldÄ±r
KULLAN: Sadece DataValidator sÄ±nÄ±fÄ±nÄ± her yerde
```

---

## ğŸ—‘ï¸ FAZLALIK #2: VectorizedBacktest SÄ±nÄ±fÄ±

**Konum:** `src/backtesting/engine.py` satÄ±r 250-320

**Problem:**
- BacktestEngine var (tam Ã¶zellikli)
- VectorizedBacktest var (basitleÅŸtirilmiÅŸ)
- Ä°kisi de aynÄ± iÅŸi yapÄ±yor
- VectorizedBacktest trade kaydÄ± tutmuyor

**AI Agent Komutu:**
```
DOSYA: src/backtesting/engine.py
SÄ°L: VectorizedBacktest sÄ±nÄ±fÄ±nÄ± tamamen kaldÄ±r
KALSIN: BacktestEngine (primary) ve EventDrivenEngine (advanced)
GÃœNCELLE: __init__.py'den VectorizedBacktest export'unu kaldÄ±r
```

---

## ğŸ—‘ï¸ FAZLALIK #3: KullanÄ±lmayan Config DosyalarÄ±

**Konum:** `config/` klasÃ¶rÃ¼

**Mevcut Dosyalar:**
- base.yaml
- development.yaml
- staging.yaml
- production.yaml
- trading_config.yaml
- feature_params.yaml
- ml_config.yaml
- risk_limits.yaml
- institutional_defaults.yaml

**Problem:** Ã‡ok fazla config dosyasÄ±, hangisinin kullanÄ±ldÄ±ÄŸÄ± belirsiz

**AI Agent Komutu:**
```
SADELEÅTIR:
1. trading_config.yaml - ANA CONFIG (her ÅŸey burada)
2. production.yaml - Sadece prod'a Ã¶zel override'lar
3. DiÄŸerlerini BÄ°RLEÅTÄ°R trading_config.yaml iÃ§ine

VEYA:
Tek config.yaml dosyasÄ± oluÅŸtur, environment bazlÄ± section'larla
```

---

# BÃ–LÃœM 4: JPMORGAN SEVÄ°YESÄ° GELÄ°ÅTÄ°RMELER

## ğŸš€ GELÄ°ÅTÄ°RME #1: Execution Quality Metrics

**Mevcut:** Sadece slippage yÃ¼zdesi var

**Gerekli:**
```
EKLE: Execution quality metrikleri
- Implementation Shortfall
- Arrival Price vs Execution Price
- VWAP vs Execution Price
- Market Impact (realized vs estimated)

RAPORDA GÃ–STER:
"Execution Quality Report"
- Ortalama slippage: 0.05%
- VWAP'a gÃ¶re performance: -0.02%
- Toplam execution cost: $45,230
```

---

## ğŸš€ GELÄ°ÅTÄ°RME #2: Risk Attribution

**Mevcut:** Toplam risk metrikleri var

**Gerekli:**
```
EKLE: Risk decomposition
- Systematic risk (market beta)
- Idiosyncratic risk (stock-specific)
- Sector risk
- Style risk (momentum, value, size)

RAPORDA GÃ–STER:
"Risk Attribution"
- Toplam Volatilite: 15%
  - Market: 8%
  - Sector: 4%
  - Stock-specific: 3%
- Active Risk: 7%
```

---

## ğŸš€ GELÄ°ÅTÄ°RME #3: Stress Testing

**Mevcut:** Monte Carlo var ama stress test yok

**Gerekli:**
```
EKLE: Historical stress scenarios
- 2008 Financial Crisis
- 2020 COVID Crash
- 2022 Rate Hike

HER SENARYO Ä°Ã‡Ä°N:
- O dÃ¶nemdeki market koÅŸullarÄ±nÄ± simÃ¼le et
- Stratejinin performansÄ±nÄ± hesapla
- Maximum loss'u gÃ¶ster

RAPORDA GÃ–STER:
"Stress Test Results"
| Scenario      | Duration | Market | Strategy | Max Loss |
|---------------|----------|--------|----------|----------|
| 2008 Crisis   | 6 months | -50%   | -25%     | -35%     |
| COVID Crash   | 1 month  | -35%   | -15%     | -20%     |
| 2022 Rates    | 9 months | -25%   | -10%     | -18%     |
```

---

## ğŸš€ GELÄ°ÅTÄ°RME #4: Liquidity Risk Monitoring

**Mevcut:** ADV kontrolÃ¼ var ama gerÃ§ek zamanlÄ± deÄŸil

**Gerekli:**
```
EKLE: Liquidity metrics
- Days to liquidate (DTL) - pozisyonu tasfiye etme sÃ¼resi
- Liquidity score per position
- Portfolio liquidity score
- Liquidation cost estimate

SINIRLAR:
- Max position ADV %: 5%
- Max portfolio DTL: 3 days
- Alert at DTL > 2 days

RAPORDA GÃ–STER:
"Liquidity Risk Report"
- Portfolio DTL: 1.5 days
- Least liquid position: XYZ (DTL: 4 days) âš ï¸
- Estimated liquidation cost: $125,000
```

---

## ğŸš€ GELÄ°ÅTÄ°RME #5: Model Decay Monitoring

**Mevcut:** Model bir kere eÄŸitiliyor, sonra kullanÄ±lÄ±yor

**Gerekli:**
```
EKLE: Model performance tracking
- Rolling out-of-sample performance
- Feature importance stability
- Prediction accuracy over time
- Model refresh triggers

MANTIK:
1. Her hafta model performansÄ±nÄ± Ã¶lÃ§
2. Son 4 hafta Sharpe < 0 ise ALERT
3. Feature importance deÄŸiÅŸimi > %30 ise ALERT
4. Otomatik retrain trigger'Ä±

RAPORDA GÃ–STER:
"Model Health Dashboard"
- Current model age: 45 days
- Rolling Sharpe (4w): 0.8 (â†“ from 1.2)
- Feature stability: 85%
- Recommendation: RETRAIN SOON
```

---

# BÃ–LÃœM 5: UYGULAMA Ã–NCELÄ°K SIRASI

## Faz 1: Kritik DÃ¼zeltmeler (Ä°LK YAPILACAK)

**Ã–ncelik 1 - Data Loading:**
```
1. generate_sample_data.py dosya adÄ± dÃ¼zeltmesi
2. timestamp kolon adÄ± dÃ¼zeltmesi
3. validate_all_data.py script'i oluÅŸtur
```

**Ã–ncelik 2 - Data Leakage:**
```
1. main.py generate_features() fonksiyonunu dÃ¼zelt
2. FeaturePipeline.fit() -> transform() akÄ±ÅŸÄ± uygula
3. Scaler parametreleri sadece train data'dan
```

**Ã–ncelik 3 - CV DÃ¼zeltmesi:**
```
1. sklearn cross_validate() kaldÄ±r
2. Manuel purged CV loop yaz
3. Leakage kontrolÃ¼ ekle
```

---

## Faz 2: Entegrasyon (Ä°KÄ°NCÄ° YAPILACAK)

**Ã–ncelik 4 - Market Impact:**
```
1. Per-symbol ADV kullanÄ±mÄ±na geÃ§
2. BacktestEngine'e symbol_adv parametresi ekle
3. Her trade iÃ§in doÄŸru ADV kullan
```

**Ã–ncelik 5 - Walk-Forward:**
```
1. Config'den walk_forward ayarlarÄ±nÄ± oku
2. WalkForwardValidator'Ä± entegre et
3. Expanding vs sliding window seÃ§eneÄŸi
```

**Ã–ncelik 6 - TimescaleDB:**
```
1. Config'de timescale ayarlarÄ± ekle
2. load_data() iÃ§inde TimescaleClient kullanÄ±mÄ±
3. Fallback: CSV loading
```

---

## Faz 3: Raporlama (ÃœÃ‡ÃœNCÃœ YAPILACAK)

**Ã–ncelik 7 - Institutional Metrics:**
```
1. DSR, PSR, MinTRL raporlara ekle
2. n_trials parametresi (test edilen strateji sayÄ±sÄ±)
3. Statistical significance gÃ¶stergesi
```

**Ã–ncelik 8 - Sensitivity Analysis:**
```
1. Cost sensitivity matrix
2. Regime-aware breakdown
3. Stress test scenarios
```

---

## Faz 4: Tek Komut Sistemi (SON YAPILACAK)

**Ã–ncelik 9 - Orchestrator:**
```
1. orchestrate.py oluÅŸtur
2. TÃ¼m adÄ±mlarÄ± sÄ±rala
3. Hata yÃ¶netimi ekle
4. Progress gÃ¶sterimi
5. Holdout validation
```

**Ã–ncelik 10 - Final Test:**
```
1. TÃ¼m sistemi baÅŸtan sona test et
2. Sample data ile full pipeline Ã§alÄ±ÅŸtÄ±r
3. RaporlarÄ± kontrol et
4. README gÃ¼ncelle
```

---

# BÃ–LÃœM 6: KALÄ°TE KONTROL CHECKLIST

## Backtest BaÅŸlamadan Ã–nce

- [ ] TÃ¼m data dosyalarÄ± validate edildi mi?
- [ ] Feature pipeline FIT train data Ã¼zerinde yapÄ±ldÄ± mÄ±?
- [ ] Purge gap doÄŸru hesaplandÄ± mÄ±? (horizon + lookback + buffer)
- [ ] Survivorship bias kontrolÃ¼ yapÄ±ldÄ± mÄ±?
- [ ] Holdout data ayrÄ±ldÄ± mÄ±?

## Backtest SÄ±rasÄ±nda

- [ ] Cash balance hiÃ§ negatif olmuyor mu?
- [ ] Market impact per-symbol ADV ile mi hesaplanÄ±yor?
- [ ] Slippage realistic mi?
- [ ] Trade execution t+1'de mi yapÄ±lÄ±yor (look-ahead yok)?

## Backtest SonrasÄ±nda

- [ ] DSR pozitif mi?
- [ ] PSR > 95% mi (statistical significance)?
- [ ] Holdout performance in-sample'a yakÄ±n mÄ±?
- [ ] Cost sensitivity makul mÃ¼?
- [ ] Regime analysis yapÄ±ldÄ± mÄ±?

---

# SONUÃ‡

Bu dÃ¶kÃ¼man AI Agent'Ä±n AlphaTrade sistemini JPMorgan seviyesine getirmesi iÃ§in gereken TÃœM adÄ±mlarÄ± iÃ§ermektedir.

**Tahmini SÃ¼re:** 
- Faz 1: 2 saat
- Faz 2: 2 saat  
- Faz 3: 1.5 saat
- Faz 4: 1 saat
- **TOPLAM: 6.5 saat**

**Kritik BaÅŸarÄ± Metrikleri:**
1. Data leakage: SIFIR
2. Purge gap: DoÄŸru hesaplanmÄ±ÅŸ
3. DSR: TÃ¼m raporlarda mevcut
4. Tek komut: `python orchestrate.py` her ÅŸeyi Ã§alÄ±ÅŸtÄ±rÄ±yor
5. Holdout validation: Out-of-sample sonuÃ§ mevcut

---

*Bu dÃ¶kÃ¼man AI Agent'a verilecek komutlar formatÄ±nda hazÄ±rlanmÄ±ÅŸtÄ±r.*
*Kod iÃ§ermez, sadece NE yapÄ±lmasÄ± gerektiÄŸini aÃ§Ä±klar.*
